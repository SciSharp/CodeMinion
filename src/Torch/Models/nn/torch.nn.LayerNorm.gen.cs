// Code generated by CodeMinion: https://github.com/SciSharp/CodeMinion

using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using Python.Runtime;
using Numpy;
using Numpy.Models;

namespace Torch
{
    public static partial class torch {
        public static partial class nn {
            /// <summary>
            ///	Applies Layer Normalization over a mini-batch of inputs as described in
            ///	the paper Layer Normalization .
            ///	
            ///	\[y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta
            ///	
            ///	\]
            ///	
            ///	The mean and standard-deviation are calculated separately over the last
            ///	certain number dimensions which have to be of the shape specified by
            ///	normalized_shape.<br></br>
            ///	
            ///	\(\gamma\) and \(\beta\) are learnable affine transform parameters of
            ///	normalized_shape if elementwise_affine is True.<br></br>
            ///	
            ///	Note
            ///	Unlike Batch Normalization and Instance Normalization, which applies
            ///	scalar scale and bias for each entire channel/plane with the
            ///	affine option, Layer Normalization applies per-element scale and
            ///	bias with elementwise_affine.<br></br>
            ///	
            ///	This layer uses statistics computed from input data in both training and
            ///	evaluation modes.
            /// </summary>
            public partial class LayerNorm : Module
            {
                // auto-generated class
                
                public LayerNorm(PyObject pyobj) : base(pyobj) { }
                
                public LayerNorm(Module other) : base(other.PyObject as PyObject) { }
                
                public LayerNorm(Shape normalized_shape, double eps = 1.0e-5, bool elementwise_affine = true)
                {
                    //auto-generated code, do not change
                    var nn = self.GetAttr("nn");
                    var __self__=nn;
                    var pyargs=ToTuple(new object[]
                    {
                        normalized_shape,
                    });
                    var kwargs=new PyDict();
                    if (eps!=1.0e-5) kwargs["eps"]=ToPython(eps);
                    if (elementwise_affine!=true) kwargs["elementwise_affine"]=ToPython(elementwise_affine);
                    dynamic py = __self__.InvokeMethod("LayerNorm", pyargs, kwargs);
                    self=py as PyObject;
                }
                
            }
        }
    }
    
}
