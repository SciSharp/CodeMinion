// Code generated by CodeMinion: https://github.com/SciSharp/CodeMinion

using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using Python.Runtime;
using Numpy;
using Numpy.Models;

namespace Torch
{
    public static partial class torch {
        public static partial class nn {
            /// <summary>
            ///	Applies a 3D transposed convolution operator over an input image composed of several input
            ///	planes.<br></br>
            ///	
            ///	The transposed convolution operator multiplies each input value element-wise by a learnable kernel,
            ///	and sums over the outputs from all input feature planes.<br></br>
            ///	
            ///	This module can be seen as the gradient of Conv3d with respect to its input.<br></br>
            ///	
            ///	It is also known as a fractionally-strided convolution or
            ///	a deconvolution (although it is not an actual deconvolution operation).<br></br>
            ///	
            ///	stride controls the stride for the cross-correlation.<br></br>
            ///	
            ///	padding controls the amount of implicit zero-paddings on both
            ///	sides for dilation * (kernel_size - 1) - padding number of points.<br></br>
            ///	 See note
            ///	below for details.<br></br>
            ///	
            ///	output_padding controls the additional size added to one side
            ///	of the output shape.<br></br>
            ///	 See note below for details.<br></br>
            ///	
            ///	dilation controls the spacing between the kernel points; also known as the à trous algorithm.<br></br>
            ///	
            ///	It is harder to describe, but this link has a nice visualization of what dilation does.<br></br>
            ///	
            ///	groups controls the connections between inputs and outputs.<br></br>
            ///	
            ///	in_channels and out_channels must both be divisible by
            ///	groups.<br></br>
            ///	 For example,
            ///	
            ///	At groups=1, all inputs are convolved to all outputs.<br></br>
            ///	
            ///	At groups=2, the operation becomes equivalent to having two conv
            ///	layers side by side, each seeing half the input channels,
            ///	and producing half the output channels, and both subsequently
            ///	concatenated.<br></br>
            ///	
            ///	At groups= in_channels, each input channel is convolved with
            ///	its own set of filters (of size
            ///	\(\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor\)).<br></br>
            ///	
            ///	The parameters kernel_size, stride, padding, output_padding
            ///	can either be:
            ///	
            ///	a single int – in which case the same value is used for the depth, height and width dimensions
            ///	a tuple of three ints – in which case, the first int is used for the depth dimension,
            ///	the second int for the height dimension and the third int for the width dimension
            ///	
            ///	Note
            ///	Depending of the size of your kernel, several (of the last)
            ///	columns of the input might be lost, because it is a valid cross-correlation,
            ///	and not a full cross-correlation.<br></br>
            ///	
            ///	It is up to the user to add proper padding.<br></br>
            ///	
            ///	Note
            ///	The padding argument effectively adds dilation * (kernel_size - 1) - padding
            ///	amount of zero padding to both sizes of the input.<br></br>
            ///	 This is set so that
            ///	when a Conv3d and a ConvTranspose3d
            ///	are initialized with same parameters, they are inverses of each other in
            ///	regard to the input and output shapes.<br></br>
            ///	 However, when stride &gt; 1,
            ///	Conv3d maps multiple input shapes to the same output
            ///	shape.<br></br>
            ///	 output_padding is provided to resolve this ambiguity by
            ///	effectively increasing the calculated output shape on one side.<br></br>
            ///	 Note
            ///	that output_padding is only used to find output shape, but does
            ///	not actually add zero-padding to output.<br></br>
            ///	
            ///	Note
            ///	In some circumstances when using the CUDA backend with CuDNN, this operator
            ///	may select a nondeterministic algorithm to increase performance.<br></br>
            ///	 If this is
            ///	undesirable, you can try to make the operation deterministic (potentially at
            ///	a performance cost) by setting torch.backends.cudnn.deterministic =
            ///	True.<br></br>
            ///	
            ///	Please see the notes on Reproducibility for background.
            /// </summary>
            public partial class ConvTranspose3d : Module
            {
                // auto-generated class
                
                public ConvTranspose3d(PyObject pyobj) : base(pyobj) { }
                
                public ConvTranspose3d(Module other) : base(other.PyObject as PyObject) { }
                
                public ConvTranspose3d(int in_channels, int out_channels, int[] kernel_size, int[] stride = null, int? padding = 0, int[] output_padding = null, int? groups = 1, bool? bias = true, int? dilation = 1)
                {
                    //auto-generated code, do not change
                    var nn = self.GetAttr("nn");
                    var __self__=nn;
                    var pyargs=ToTuple(new object[]
                    {
                        in_channels,
                        out_channels,
                        kernel_size,
                    });
                    var kwargs=new PyDict();
                    if (stride!=null) kwargs["stride"]=ToPython(stride);
                    if (padding!=0) kwargs["padding"]=ToPython(padding);
                    if (output_padding!=null) kwargs["output_padding"]=ToPython(output_padding);
                    if (groups!=1) kwargs["groups"]=ToPython(groups);
                    if (bias!=true) kwargs["bias"]=ToPython(bias);
                    if (dilation!=1) kwargs["dilation"]=ToPython(dilation);
                    dynamic py = __self__.InvokeMethod("ConvTranspose3d", pyargs, kwargs);
                    self=py as PyObject;
                }
                
            }
        }
    }
    
}
