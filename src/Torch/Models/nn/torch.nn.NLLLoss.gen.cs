// Code generated by CodeMinion: https://github.com/SciSharp/CodeMinion

using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using Python.Runtime;
using Numpy;
using Numpy.Models;

namespace Torch
{
    public static partial class torch {
        public static partial class nn {
            /// <summary>
            ///	The negative log likelihood loss.<br></br>
            ///	 It is useful to train a classification
            ///	problem with C classes.<br></br>
            ///	
            ///	If provided, the optional argument weight should be a 1D Tensor assigning
            ///	weight to each of the classes.<br></br>
            ///	 This is particularly useful when you have an
            ///	unbalanced training set.<br></br>
            ///	
            ///	The input given through a forward call is expected to contain
            ///	log-probabilities of each class.<br></br>
            ///	 input has to be a Tensor of size either
            ///	\((minibatch, C)\) or \((minibatch, C, d_1, d_2, ..., d_K)\)
            ///	with \(K \geq 1\) for the K-dimensional case (described later).<br></br>
            ///	
            ///	Obtaining log-probabilities in a neural network is easily achieved by
            ///	adding a  LogSoftmax  layer in the last layer of your network.<br></br>
            ///	
            ///	You may use CrossEntropyLoss instead, if you prefer not to add an extra
            ///	layer.<br></br>
            ///	
            ///	The target that this loss expects should be a class index in the range \([0, C-1]\)
            ///	where C = number of classes; if ignore_index is specified, this loss also accepts
            ///	this class index (this index may not necessarily be in the class range).<br></br>
            ///	
            ///	The unreduced (i.e.<br></br>
            ///	 with reduction set to 'none') loss can be described as:
            ///	
            ///	\[\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
            ///	l_n = - w_{y_n} x_{n,y_n}, \quad
            ///	w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},
            ///	
            ///	\]
            ///	
            ///	where \(N\) is the batch size.<br></br>
            ///	 If reduction is not 'none'
            ///	(default 'mean'), then
            ///	
            ///	\[\ell(x, y) = \begin{cases}
            ///	    \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &
            ///	    \text{if reduction} = \text{'mean';}\\
            ///	    \sum_{n=1}^N l_n,  &
            ///	    \text{if reduction} = \text{'sum'.}
            ///	\end{cases}
            ///	
            ///	\]
            ///	
            ///	Can also be used for higher dimension inputs, such as 2D images, by providing
            ///	an input of size \((minibatch, C, d_1, d_2, ..., d_K)\) with \(K \geq 1\),
            ///	where \(K\) is the number of dimensions, and a target of appropriate shape
            ///	(see below).<br></br>
            ///	 In the case of images, it computes NLL loss per-pixel.
            /// </summary>
            public partial class NLLLoss : Module
            {
                // auto-generated class
                
                public NLLLoss(PyObject pyobj) : base(pyobj) { }
                
                public NLLLoss(Module other) : base(other.PyObject as PyObject) { }
                
                public NLLLoss(Tensor weight = null, bool? size_average = null, int? ignore_index = -100, bool? reduce = null, string reduction = "mean")
                {
                    //auto-generated code, do not change
                    var nn = self.GetAttr("nn");
                    var __self__=nn;
                    var pyargs=ToTuple(new object[]
                    {
                    });
                    var kwargs=new PyDict();
                    if (weight!=null) kwargs["weight"]=ToPython(weight);
                    if (size_average!=null) kwargs["size_average"]=ToPython(size_average);
                    if (ignore_index!=-100) kwargs["ignore_index"]=ToPython(ignore_index);
                    if (reduce!=null) kwargs["reduce"]=ToPython(reduce);
                    if (reduction!="mean") kwargs["reduction"]=ToPython(reduction);
                    dynamic py = __self__.InvokeMethod("NLLLoss", pyargs, kwargs);
                    self=py as PyObject;
                }
                
            }
        }
    }
    
}
