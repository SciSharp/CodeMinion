// Code generated by CodeMinion: https://github.com/SciSharp/CodeMinion

using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using Python.Runtime;
using Numpy;
using Numpy.Models;

namespace Torch
{
    public static partial class torch {
        public static partial class nn {
            /// <summary>
            ///	Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.<br></br>
            ///	
            ///	For each element in the input sequence, each layer computes the following
            ///	function:
            ///	
            ///	\[\begin{array}{ll}
            ///	    r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
            ///	    z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\
            ///	    n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
            ///	    h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}
            ///	\end{array}
            ///	
            ///	\]
            ///	
            ///	where \(h_t\) is the hidden state at time t, \(x_t\) is the input
            ///	at time t, \(h_{(t-1)}\) is the hidden state of the layer
            ///	at time t-1 or the initial hidden state at time 0, and \(r_t\),
            ///	\(z_t\), \(n_t\) are the reset, update, and new gates, respectively.<br></br>
            ///	
            ///	\(\sigma\) is the sigmoid function, and \(*\) is the Hadamard product.<br></br>
            ///	
            ///	In a multilayer GRU, the input \(x^{(l)}_t\) of the \(l\) -th layer
            ///	(\(l &gt;= 2\)) is the hidden state \(h^{(l-1)}_t\) of the previous layer multiplied by
            ///	dropout \(\delta^{(l-1)}_t\) where each \(\delta^{(l-1)}_t\) is a Bernoulli random
            ///	variable which is \(0\) with probability dropout.
            /// </summary>
            public partial class GRU : Module
            {
                // auto-generated class
                
                public GRU(PyObject pyobj) : base(pyobj) { }
                
                public GRU(Module other) : base(other.PyObject as PyObject) { }
                
                public GRU(int input_size, int hidden_size, int num_layers = 1, bool bias = true, bool batch_first = false, int dropout = 0, bool bidirectional = false)
                {
                    //auto-generated code, do not change
                    var nn = self.GetAttr("nn");
                    var __self__=nn;
                    var pyargs=ToTuple(new object[]
                    {
                        input_size,
                        hidden_size,
                    });
                    var kwargs=new PyDict();
                    if (num_layers!=1) kwargs["num_layers"]=ToPython(num_layers);
                    if (bias!=true) kwargs["bias"]=ToPython(bias);
                    if (batch_first!=false) kwargs["batch_first"]=ToPython(batch_first);
                    if (dropout!=0) kwargs["dropout"]=ToPython(dropout);
                    if (bidirectional!=false) kwargs["bidirectional"]=ToPython(bidirectional);
                    dynamic py = __self__.InvokeMethod("GRU", pyargs, kwargs);
                    self=py as PyObject;
                }
                
            }
        }
    }
    
}
