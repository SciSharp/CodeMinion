// Code generated by CodeMinion: https://github.com/SciSharp/CodeMinion

using System;
using System.Collections;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using System.Runtime.InteropServices;
using System.Text;
using Python.Runtime;
using Numpy;
using Numpy.Models;

using Microsoft.VisualStudio.TestTools.UnitTesting;
using Assert = NUnit.Framework.Assert;

namespace Torch.UnitTest
{
    [TestClass]
    public class ModuleTest : BaseTestCase
    {
        
        [TestMethod]
        public void applyTest()
        {
            // >>> def init_weights(m):
            // >>>     print(m)
            // >>>     if type(m) == nn.Linear:
            // >>>         m.weight.data.fill_(1.0)
            // >>>         print(m.weight)
            // >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))
            // >>> net.apply(init_weights)
            // Linear(in_features=2, out_features=2, bias=True)
            // Parameter containing:
            // tensor([[ 1.,  1.],
            //         [ 1.,  1.]])
            // Linear(in_features=2, out_features=2, bias=True)
            // Parameter containing:
            // tensor([[ 1.,  1.],
            //         [ 1.,  1.]])
            // Sequential(
            //   (0): Linear(in_features=2, out_features=2, bias=True)
            //   (1): Linear(in_features=2, out_features=2, bias=True)
            // )
            // Sequential(
            //   (0): Linear(in_features=2, out_features=2, bias=True)
            //   (1): Linear(in_features=2, out_features=2, bias=True)
            // )
            // 
            
            #if TODO
            var given=  def init_weights(m):;
             given=      print(m);
             given=      if type(m) == nn.Linear:;
             given=          m.weight.data.fill_(1.0);
             given=          print(m.weight);
             given=  net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2));
             given=  net.apply(init_weights);
            var expected=
                "Linear(in_features=2, out_features=2, bias=True)\n" +
                "Parameter containing:\n" +
                "tensor([[ 1.,  1.],\n" +
                "        [ 1.,  1.]])\n" +
                "Linear(in_features=2, out_features=2, bias=True)\n" +
                "Parameter containing:\n" +
                "tensor([[ 1.,  1.],\n" +
                "        [ 1.,  1.]])\n" +
                "Sequential(\n" +
                "  (0): Linear(in_features=2, out_features=2, bias=True)\n" +
                "  (1): Linear(in_features=2, out_features=2, bias=True)\n" +
                ")\n" +
                "Sequential(\n" +
                "  (0): Linear(in_features=2, out_features=2, bias=True)\n" +
                "  (1): Linear(in_features=2, out_features=2, bias=True)\n" +
                ")";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void buffersTest()
        {
            // >>> for buf in model.buffers():
            // >>>     print(type(buf.data), buf.size())
            // <class 'torch.FloatTensor'> (20L,)
            // <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)
            // 
            
            #if TODO
            var given=  for buf in model.buffers():;
             given=      print(type(buf.data), buf.size());
            var expected=
                "<class 'torch.FloatTensor'> (20L,)\n" +
                "<class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void modulesTest()
        {
            // >>> l = nn.Linear(2, 2)
            // >>> net = nn.Sequential(l, l)
            // >>> for idx, m in enumerate(net.modules()):
            //         print(idx, '->', m)
            // 
            // 0 -> Sequential(
            //   (0): Linear(in_features=2, out_features=2, bias=True)
            //   (1): Linear(in_features=2, out_features=2, bias=True)
            // )
            // 1 -> Linear(in_features=2, out_features=2, bias=True)
            // 
            
            #if TODO
            var given=  l = nn.Linear(2, 2);
             given=  net = nn.Sequential(l, l);
             given=  for idx, m in enumerate(net.modules()):;
            var expected=
                "        print(idx, '->', m)\n" +
                "\n" +
                "0 -> Sequential(\n" +
                "  (0): Linear(in_features=2, out_features=2, bias=True)\n" +
                "  (1): Linear(in_features=2, out_features=2, bias=True)\n" +
                ")\n" +
                "1 -> Linear(in_features=2, out_features=2, bias=True)";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void named_buffersTest()
        {
            // >>> for name, buf in self.named_buffers():
            // >>>    if name in ['running_var']:
            // >>>        print(buf.size())
            // 
            
            #if TODO
            var given=  for name, buf in self.named_buffers():;
             given=     if name in ['running_var']:;
             given=         print(buf.size());
            #endif
        }
        
        
        [TestMethod]
        public void named_childrenTest()
        {
            // >>> for name, module in model.named_children():
            // >>>     if name in ['conv4', 'conv5']:
            // >>>         print(module)
            // 
            
            #if TODO
            var given=  for name, module in model.named_children():;
             given=      if name in ['conv4', 'conv5']:;
             given=          print(module);
            #endif
        }
        
        
        [TestMethod]
        public void named_modulesTest()
        {
            // >>> l = nn.Linear(2, 2)
            // >>> net = nn.Sequential(l, l)
            // >>> for idx, m in enumerate(net.named_modules()):
            //         print(idx, '->', m)
            // 
            // 0 -> ('', Sequential(
            //   (0): Linear(in_features=2, out_features=2, bias=True)
            //   (1): Linear(in_features=2, out_features=2, bias=True)
            // ))
            // 1 -> ('0', Linear(in_features=2, out_features=2, bias=True))
            // 
            
            #if TODO
            var given=  l = nn.Linear(2, 2);
             given=  net = nn.Sequential(l, l);
             given=  for idx, m in enumerate(net.named_modules()):;
            var expected=
                "        print(idx, '->', m)\n" +
                "\n" +
                "0 -> ('', Sequential(\n" +
                "  (0): Linear(in_features=2, out_features=2, bias=True)\n" +
                "  (1): Linear(in_features=2, out_features=2, bias=True)\n" +
                "))\n" +
                "1 -> ('0', Linear(in_features=2, out_features=2, bias=True))";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void named_parametersTest()
        {
            // >>> for name, param in self.named_parameters():
            // >>>    if name in ['bias']:
            // >>>        print(param.size())
            // 
            
            #if TODO
            var given=  for name, param in self.named_parameters():;
             given=     if name in ['bias']:;
             given=         print(param.size());
            #endif
        }
        
        
        [TestMethod]
        public void parametersTest()
        {
            // >>> for param in model.parameters():
            // >>>     print(type(param.data), param.size())
            // <class 'torch.FloatTensor'> (20L,)
            // <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)
            // 
            
            #if TODO
            var given=  for param in model.parameters():;
             given=      print(type(param.data), param.size());
            var expected=
                "<class 'torch.FloatTensor'> (20L,)\n" +
                "<class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void register_backward_hookTest()
        {
            // hook(module, grad_input, grad_output) -> Tensor or None
            // 
            
            #if TODO
            var expected=
                "hook(module, grad_input, grad_output) -> Tensor or None";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void register_bufferTest()
        {
            // >>> self.register_buffer('running_mean', torch.zeros(num_features))
            // 
            
            #if TODO
            var given=  self.register_buffer('running_mean', torch.zeros(num_features));
            #endif
        }
        
        
        [TestMethod]
        public void register_forward_hookTest()
        {
            // hook(module, input, output) -> None
            // 
            
            #if TODO
            var expected=
                "hook(module, input, output) -> None";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void register_forward_pre_hookTest()
        {
            // hook(module, input) -> None
            // 
            
            #if TODO
            var expected=
                "hook(module, input) -> None";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void state_dictTest()
        {
            // >>> module.state_dict().keys()
            // ['bias', 'weight']
            // 
            
            #if TODO
            var given=  module.state_dict().keys();
            var expected=
                "['bias', 'weight']";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
        
        [TestMethod]
        public void toTest()
        {
            // >>> linear = nn.Linear(2, 2)
            // >>> linear.weight
            // Parameter containing:
            // tensor([[ 0.1913, -0.3420],
            //         [-0.5113, -0.2325]])
            // >>> linear.to(torch.double)
            // Linear(in_features=2, out_features=2, bias=True)
            // >>> linear.weight
            // Parameter containing:
            // tensor([[ 0.1913, -0.3420],
            //         [-0.5113, -0.2325]], dtype=torch.float64)
            // >>> gpu1 = torch.device("cuda:1")
            // >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)
            // Linear(in_features=2, out_features=2, bias=True)
            // >>> linear.weight
            // Parameter containing:
            // tensor([[ 0.1914, -0.3420],
            //         [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')
            // >>> cpu = torch.device("cpu")
            // >>> linear.to(cpu)
            // Linear(in_features=2, out_features=2, bias=True)
            // >>> linear.weight
            // Parameter containing:
            // tensor([[ 0.1914, -0.3420],
            //         [-0.5112, -0.2324]], dtype=torch.float16)
            // 
            
            #if TODO
            var given=  linear = nn.Linear(2, 2);
             given=  linear.weight;
            var expected=
                "Parameter containing:\n" +
                "tensor([[ 0.1913, -0.3420],\n" +
                "        [-0.5113, -0.2325]])";
            Assert.AreEqual(expected, given.repr);
             given=  linear.to(torch.double);
             expected=
                "Linear(in_features=2, out_features=2, bias=True)";
            Assert.AreEqual(expected, given.repr);
             given=  linear.weight;
             expected=
                "Parameter containing:\n" +
                "tensor([[ 0.1913, -0.3420],\n" +
                "        [-0.5113, -0.2325]], dtype=torch.float64)";
            Assert.AreEqual(expected, given.repr);
             given=  gpu1 = torch.device("cuda:1");
             given=  linear.to(gpu1, dtype=torch.half, non_blocking=True);
             expected=
                "Linear(in_features=2, out_features=2, bias=True)";
            Assert.AreEqual(expected, given.repr);
             given=  linear.weight;
             expected=
                "Parameter containing:\n" +
                "tensor([[ 0.1914, -0.3420],\n" +
                "        [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')";
            Assert.AreEqual(expected, given.repr);
             given=  cpu = torch.device("cpu");
             given=  linear.to(cpu);
             expected=
                "Linear(in_features=2, out_features=2, bias=True)";
            Assert.AreEqual(expected, given.repr);
             given=  linear.weight;
             expected=
                "Parameter containing:\n" +
                "tensor([[ 0.1914, -0.3420],\n" +
                "        [-0.5112, -0.2324]], dtype=torch.float16)";
            Assert.AreEqual(expected, given.repr);
            #endif
        }
        
    }
}
